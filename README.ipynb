{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Text Generation\n",
    "\n",
    "One interesting problem in artificial intelligence is the . It is one of the oldest questions in computer intelligence, posed formally in the [Turing Test](https://en.wikipedia.org/wiki/Turing_test), which tests whether not a computer can be nidistinguishable from a human in a text only chat. This model however stays far away from such a task, instead attempts to generate new recourse from a single speaker based on a corpus of recorded speech or writing.\n",
    "\n",
    "We work here with deterministic, probability based models. Building from low to high complexity, we will build and evaluate several different types of models.\n",
    "This model is based on [Markov Chains](https://en.wikipedia.org/wiki/Markov_chain), where we record for every unique word, what is the distribution of words that come after that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a markov chain order zero, where we do not take any progresssion of words into account. Instead, each word is randomly selected from the corpus. T\n",
    "\n",
    "We can accomplish this using the corpus module by calling model zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recourse\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example I will be using speeches given by Dr. Martin Luther King Jr. I selected him not only for his imprtance but also his characteristic style of speeh, which I wanted to see how well this model could capture. The test is from Richten Park Public LIbrary, and the download for the original document can be found [here](wmasd.ss7.sharpschool.com/common/pages/UserFile.aspx?fileId=8373388).\n",
    "\n",
    "A text file is in this repository of a cleaner version of this pdf, however it still contains a lot of puncuation and requires just a little more prep before it is ready to go into a model. We need an all lower case list of the words in order without puncuation (discussion of the impact of this on the model will be discussed later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"king.txt\",\"r\")\n",
    "text = corpus.read() \n",
    "corpus.close()\n",
    "text = re.sub(\"[^A-Za-z0-9 ]+\", \"\", text)\n",
    "text = text.split()\n",
    "text = [word.lower() for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'chairman',\n",
       " 'distinguished',\n",
       " 'platform',\n",
       " 'associates',\n",
       " 'fellow',\n",
       " 'americans',\n",
       " 'three',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'the',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'of',\n",
       " 'this',\n",
       " 'nation',\n",
       " 'rendered',\n",
       " 'in',\n",
       " 'simple',\n",
       " 'eloquent']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let us take just about the simplest way to generate text based on a corpus we could think up, and have each generated word simply be randomly sampled from the corpus. This can be accomplished with the ```zero_model``` class within the recourse module. First we will build the model, and then use the function ```gen``` to create new sentences of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = recourse.zero_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a then a the laughing mercy vast hates must must love the a and to affirmation course ended the that thing georgia jerusalem sir on north is for able was been places the you in often light master dont they'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.gen(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appraoch performs about as well as we could expect, while "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = recourse.one_word_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these models have their moments, there is room for a lot of improvement. Chief amoung these is the lack of any way to define sentences, it just goes on until . I think a more intuitive way to build speech would be instead to ask the model for a certain number of *sentences*\n",
    "from naive to more complex:\n",
    "1. Determine the distribution of sentence lengths in the corpus and sample from that distribution to decide where to place commas\n",
    "2. Keep the words that end sentences as denoted by ending in a \".\" distinct from the same words that does not. For example \"things\" would be a different word in the model, and have different movement probabilites than \"things.\" \n",
    "\n",
    "The first option is computationally very cheapbut would add very little to the quality of the generator rhetoric. It would only serve to punctuate  \n",
    "This way the sentences would also be guaranteed to start with a word that begins at least one sentence in the text. It does however have the pitfall that there would most likely be many sentence ending / beginning words that are unique. That is to say, that if a certain word ends a sentence, the start of the next sentence would be deterministic instead of random."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
