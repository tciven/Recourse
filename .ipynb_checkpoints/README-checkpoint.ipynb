{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Text Generation\n",
    "\n",
    "One interesting problem in artificial intelligence is the . It is one of the oldest questions in computer intelligence, posed formally in the [Turing Test](https://en.wikipedia.org/wiki/Turing_test), which tests whether not a computer can be nidistinguishable from a human in a text only chat. This model however stays far away from such a task, instead attempts to generate new recourse from a single speaker based on a corpus of recorded speech or writing.\n",
    "\n",
    "We work here with deterministic, probability based models. Building from low to high complexity, we will build and evaluate several different types of models.\n",
    "This model is based on [Markov Chains](https://en.wikipedia.org/wiki/Markov_chain), where we record for every unique word, what is the distribution of words that come after that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a markov chain order zero, where we do not take any progresssion of words into account. Instead, each word is randomly selected from the corpus. T\n",
    "\n",
    "We can accomplish this using the corpus module by calling model zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recourse\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example I will be using speeches given by Dr. Martin Luther King Jr. I selected him not only for his imprtance but also his characteristic style of speeh, which I wanted to see how well this model could capture. The test is from Richten Park Public LIbrary, and the download for the original document can be found [here](wmasd.ss7.sharpschool.com/common/pages/UserFile.aspx?fileId=8373388).\n",
    "\n",
    "A text file is in this repository of a cleaner version of this pdf, however it still contains a lot of puncuation and requires just a little more prep before it is ready to go into a model. We need an all lower case list of the words in order without puncuation (discussion of the impact of this on the model will be discussed later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"king.txt\",\"r\")\n",
    "text = corpus.read() \n",
    "corpus.close()\n",
    "text = re.sub(\"[^A-Za-z0-9 ]+\", \"\", text)\n",
    "text = text.split()\n",
    "text = [word.lower() for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'chairman',\n",
       " 'distinguished',\n",
       " 'platform',\n",
       " 'associates',\n",
       " 'fellow',\n",
       " 'americans',\n",
       " 'three',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'the',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'of',\n",
       " 'this',\n",
       " 'nation',\n",
       " 'rendered',\n",
       " 'in',\n",
       " 'simple',\n",
       " 'eloquent']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let us take just about the simplest way to generate text based on a corpus we could think up, and have each generated word simply be randomly sampled from the corpus. This can be accomplished with the ```zero_model``` class within the recourse module. First we will build the model, and then use the function ```gen``` to create new sentences of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = recourse.zero_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a then a the laughing mercy vast hates must must love the a and to affirmation course ended the that thing georgia jerusalem sir on north is for able was been places the you in often light master dont they'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.gen(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = recourse.one_word_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
